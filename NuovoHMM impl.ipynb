{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "import sys\n",
    "import time\n",
    "import copy\n",
    "from IPython.display import clear_output\n",
    "\n",
    "#Setting up the dictionary\n",
    "posDictionary = {}\n",
    "posDictionary['ADJ'] = 0\n",
    "posDictionary['ADP'] = 1\n",
    "posDictionary['ADV'] = 2\n",
    "posDictionary['AUX'] = 3\n",
    "posDictionary['CCONJ'] = 4\n",
    "posDictionary['DET'] = 5\n",
    "posDictionary['INTJ'] = 6\n",
    "posDictionary['NOUN'] = 7\n",
    "posDictionary['NUM'] = 8\n",
    "posDictionary['PART'] = 9\n",
    "posDictionary['PRON'] = 10\n",
    "posDictionary['PROPN'] = 11\n",
    "posDictionary['PUNCT'] = 12\n",
    "posDictionary['SCONJ'] = 13\n",
    "posDictionary['SYM'] = 14\n",
    "posDictionary['VERB'] = 15\n",
    "posDictionary['X'] = 16\n",
    "\n",
    "reverseDictionary = {}\n",
    "reverseDictionary['0'] = 'ADJ'\n",
    "reverseDictionary['1'] = 'ADP'\n",
    "reverseDictionary['2'] = 'ADV'\n",
    "reverseDictionary['3'] = 'AUX'\n",
    "reverseDictionary['4'] = 'CCONJ'\n",
    "reverseDictionary['5'] = 'DET'\n",
    "reverseDictionary['6'] = 'INTJ'\n",
    "reverseDictionary['7'] = 'NOUN'\n",
    "reverseDictionary['8'] = 'NUM'\n",
    "reverseDictionary['9'] = 'PART'\n",
    "reverseDictionary['10'] = 'PRON'\n",
    "reverseDictionary['11'] = 'PROPN'\n",
    "reverseDictionary['12'] = 'PUNCT'\n",
    "reverseDictionary['13'] = 'SCONJ'\n",
    "reverseDictionary['14'] = 'SYM'\n",
    "reverseDictionary['15'] = 'VERB'\n",
    "reverseDictionary['16'] = 'X'\n",
    "\n",
    "#Opening the training set file \n",
    "with open(\"ud21_for_POS_TAGGING-180325-train.txt\", encoding=\"utf-8\") as f:\n",
    "    reader = csv.reader(f, delimiter=\"\\t\", quotechar=None)\n",
    "    wordsArray = list(reader)\n",
    "\n",
    "#Creating the Part of Speech list: dimension=367760x1\n",
    "posList=[]\n",
    "for i in range(0,len(wordsArray)):\n",
    "    posList.append(wordsArray[i][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Creating the Part of Speech set: dimension=17x1\n",
    "posSet = sorted(set(posList))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Creating:\n",
    "#          1: the array containing P(t_0 | start)\n",
    "#          2: the array containing P(end | t_last)\n",
    "\n",
    "tagStart = np.zeros(len(posSet))\n",
    "totalPunct = 0\n",
    "for i in range(1, len(wordsArray)-1):\n",
    "    #Everytime we find a PUNCT we consider the next tag(wordsArray[i+1][1])\n",
    "    if(wordsArray[i][0] == '.'):\n",
    "        totalPunct += 1\n",
    "        tagStart[posDictionary[wordsArray[i+1][1]]] += 1\n",
    "\n",
    "for i in range(0, len(tagStart)):\n",
    "    tagStart[i] /= totalPunct-1    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PoS tag set is: \n",
      "['ADJ', 'ADP', 'ADV', 'AUX', 'CCONJ', 'DET', 'INTJ', 'NOUN', 'NUM', 'PART', 'PRON', 'PROPN', 'PUNCT', 'SCONJ', 'SYM', 'VERB', 'X']\n"
     ]
    }
   ],
   "source": [
    "#Creating:\n",
    "#          1: the matrix that count C(t_{i}, t_{i-1}): dimension=17x17\n",
    "#          2: the array that count C(t_{i}): dimension=17x1\n",
    "print(\"PoS tag set is: \")\n",
    "print(posSet)\n",
    "tagCount = np.zeros(len(posSet))\n",
    "tagConjCount = np.zeros((len(posSet), len(posSet)))\n",
    "tagCount[posDictionary[posList[0]]] +=1\n",
    "\n",
    "for i in range(1, len(posList)):\n",
    "    currentTag = posList[i]\n",
    "    prevTag = posList[i-1]\n",
    "    \n",
    "    tagCount[posDictionary[currentTag]] +=1\n",
    "    tagConjCount[posDictionary[currentTag], posDictionary[prevTag]] +=1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Creating array containing the conditional probability\n",
    "tagCondProb = np.zeros((len(posSet), len(posSet)))\n",
    "for i in range(0, len(posSet)):\n",
    "    for j in range(0, len(posSet)):\n",
    "        tagCondProb[i][j] = tagConjCount[i][j]/tagCount[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Building wordStructure to make efficient the buildEmission function\n",
    "wordsArrayCopy = np.array(copy.copy(wordsArray))\n",
    "for i in range(0, len(wordsArrayCopy)):\n",
    "    wordsArrayCopy[i][0] = wordsArrayCopy[i][0].lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "367760/367760\n"
     ]
    }
   ],
   "source": [
    "wordSet = sorted(set(wordsArrayCopy[:,0]))\n",
    "wordStructure = np.zeros((len(wordSet), len(posSet)))\n",
    "\n",
    "for i in range(0, len(wordsArrayCopy)):\n",
    "    if(i%10000==0):\n",
    "        clear_output()\n",
    "        print(str(i)+\"/\"+str(len(wordsArrayCopy)))\n",
    "    position = wordSet.index(wordsArrayCopy[i][0])\n",
    "    wordStructure[position][posDictionary[wordsArrayCopy[i][1]]] += 1\n",
    "    \n",
    "clear_output()\n",
    "print(str(len(wordsArrayCopy))+\"/\"+str(len(wordsArrayCopy)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Normalizing\n",
    "for i in range(0,len(wordSet)):\n",
    "    occur = 0\n",
    "    for j in range(0, len(posSet)):\n",
    "        occur += wordStructure[i][j]\n",
    "    wordStructure[i] = wordStructure[i] / occur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Building emission probability matrix\n",
    "def buildEmission(phrase, posSet):\n",
    "    emissionMatrix = np.zeros((len(phrase), len(posSet)))\n",
    "    #for every word in the training set\n",
    "    for j in range(0, len(phrase)):\n",
    "        if(phrase[j].lower() in wordSet):\n",
    "            currentWordPos = wordSet.index(phrase[j].lower())\n",
    "            emissionMatrix[j] = wordStructure[currentWordPos]\n",
    "        else:\n",
    "            emissionMatrix[j] = 1/len(posSet)\n",
    "    return emissionMatrix\n",
    "\n",
    "#print(buildEmission(['È', \"la\", \"spada\", \"laser\", \"di\", \"tuo\", \"padre\"], posSet))\n",
    "\n",
    "#Defining Viterbi Algorithm\n",
    "def viterbiAlgorithm(phrase, posSet):\n",
    "    viterbiMatrix = np.zeros((len(posSet), len(phrase)))\n",
    "    backpointerMatrix = np.zeros((len(posSet), len(phrase)))\n",
    "    emissionMatrix = buildEmission(phrase, posSet)\n",
    "    \n",
    "    #Initialization step\n",
    "    for i in range(0, len(posSet)):\n",
    "        viterbiMatrix[i][0] = tagStart[i] * emissionMatrix[0][i]\n",
    "          \n",
    "    #Recursion step\n",
    "    for i in range(1, len(phrase)):\n",
    "        for j in range(0, len(posSet)):\n",
    "            maxProb = -1\n",
    "            maxIndex = -1\n",
    "            for k in range(0, len(posSet)):\n",
    "                currentProb = viterbiMatrix[k][i-1] * tagCondProb[j][k] * emissionMatrix[i][j]\n",
    "                \n",
    "                if(currentProb>maxProb):\n",
    "                    maxProb = currentProb\n",
    "                    maxIndex = k\n",
    "            viterbiMatrix[j][i]=maxProb\n",
    "            backpointerMatrix[j][i] = maxIndex\n",
    "          \n",
    "    return [viterbiMatrix, backpointerMatrix]\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def viterbi(phrases, posSet):\n",
    "    phrasesArray =[]\n",
    "    for p in range(0, len(phrases)):\n",
    "        if(p % 100 == 0):\n",
    "            clear_output()\n",
    "            print(str(p)+\"/\"+str(len(phrases)))\n",
    "        \n",
    "        viterbiResults = viterbiAlgorithm(phrases[p], posSet)\n",
    "\n",
    "        #Getting the max probability index from Viterbi Matrix\n",
    "        maxIndexProb = np.argmax(viterbiResults[0][:,len(phrases[p])-1])\n",
    "        \n",
    "        phraseClassArray = []\n",
    "        \n",
    "        phraseClassArray.append(reverseDictionary[str(maxIndexProb)])\n",
    "        currentBackpointerIndex = int(viterbiResults[1][maxIndexProb][len(phrases[p])-1])\n",
    "\n",
    "        #Getting the PoS sequence\n",
    "        for i in range(len(phrases[p])-2, -1, -1):\n",
    "            phraseClassArray.insert(0, reverseDictionary[str(currentBackpointerIndex)])\n",
    "            currentBackpointerIndex = int(viterbiResults[1][currentBackpointerIndex][i])\n",
    "            \n",
    "        phrasesArray.append(phraseClassArray)\n",
    "    \n",
    "    clear_output()\n",
    "    print(str(len(phrases))+\"/\"+str(len(phrases)))\n",
    "    return phrasesArray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3\n",
      "TOTAL time: 0.0351102352142334\n",
      "[['AUX', 'DET', 'NOUN', 'NOUN', 'ADP', 'DET', 'NOUN'], ['AUX', 'VERB', 'DET', 'NOUN', 'ADJ'], ['DET', 'ADJ', 'NOUN', 'PROPN', 'ADJ', 'NOUN', 'AUX', 'AUX', 'VERB', 'ADP']]\n"
     ]
    }
   ],
   "source": [
    "#Testing the algorithm on the three sample phrase given by the teacher\n",
    "phrasesSample = [['È', \"la\", \"spada\", \"laser\", \"di\", \"tuo\", \"padre\"], [\"Ha\", \"fatto\", \"una\", \"mossa\", \"leale\"], [\"Gli\", \"ultimi\", \"avanzi\", \"della\", \"vecchia\", \"Repubblica\", \"sono\", \"stati\", \"spazzati\", \"via\"]] \n",
    "\n",
    "start_time_total = time.time()\n",
    "resSample = viterbi(phrasesSample, posSet)\n",
    "end_time_total = time.time()\n",
    "print(\"TOTAL time: {}\".format(end_time_total - start_time_total))\n",
    "\n",
    "print(resSample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#ACCURACY\n",
    "#Opening the test set file \n",
    "with open(\"ud21_for_POS_TAGGING-180325-test.txt\", encoding=\"utf-8\") as f:\n",
    "    reader = csv.reader(f, delimiter=\"\\t\", quotechar=None)\n",
    "    wordsArrayTest = list(reader)\n",
    "\n",
    "#Creating the Part of Speech list: dimension=20254x1\n",
    "posListTest=[]\n",
    "for i in range(0,len(wordsArrayTest)):\n",
    "    posListTest.append(wordsArrayTest[i][1])\n",
    "\n",
    "phrases=[]\n",
    "tagsList = []\n",
    "currentPhrase = []\n",
    "currentTagList = []\n",
    "for i in range(0, len(wordsArrayTest)):\n",
    "    #Everytime we find a '.' we consider the current phrase as ended\n",
    "    if(wordsArrayTest[i][0] == '.'):\n",
    "        currentPhrase.append(wordsArrayTest[i][0])\n",
    "        currentTagList.append(posListTest[i])\n",
    "        phrases.append(currentPhrase)\n",
    "        tagsList.append(currentTagList)\n",
    "        currentPhrase =[]\n",
    "        currentTagList=[]\n",
    "    else:\n",
    "        currentPhrase.append(wordsArrayTest[i][0])\n",
    "        currentTagList.append(posListTest[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 670 in the test set\n"
     ]
    }
   ],
   "source": [
    "#Number of phrases in the test set\n",
    "print(\"There are \" + str(len(phrases)) + \" in the test set\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0/670\n"
     ]
    }
   ],
   "source": [
    "#Executing Viterbi algorithm over the test set\n",
    "start_time_long = time.time()\n",
    "res = viterbi(phrases, posSet)\n",
    "end_time_long = time.time()\n",
    "print(\"TOTAL time: {}\".format(end_time_long - start_time_long))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct is 18487\n",
      "Total is 20254\n",
      "Accuracy is 0.9127579737335835\n"
     ]
    }
   ],
   "source": [
    "#Accuracy calculation\n",
    "correct = 0\n",
    "total = 0\n",
    "for i in range(0, len(res)):\n",
    "    for j in range(0, len(res[i])):\n",
    "        if(res[i][j] == tagsList[i][j]):\n",
    "            correct += 1\n",
    "        total +=1\n",
    "print(\"Correct is \"+ str(correct))\n",
    "print(\"Total is \"+str(total))\n",
    "print(\"Accuracy is \" + str(correct/total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31367/31367\n"
     ]
    }
   ],
   "source": [
    "#Creating the array that contains the most frequent tag for every word\n",
    "wordsMostFreqUse = []\n",
    "for i in range(0, len(wordSet)):\n",
    "    if(i%500==0):\n",
    "        clear_output()\n",
    "        print(str(i)+\"/\"+str(len(wordSet)))\n",
    "        \n",
    "    wordsMostFreqUse.append([wordSet[i], np.argmax(wordStructure[i])])\n",
    "\n",
    "clear_output()\n",
    "print(str(len(wordSet))+\"/\"+str(len(wordSet)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#BASELINE ACCURACY\n",
    "baselineRes = []\n",
    "for i in range(0, len(wordsArrayTest)):\n",
    "    currentWord = wordsArrayTest[i][0].lower()\n",
    "    \n",
    "    if(currentWord in wordSet):\n",
    "        currentWordPos = wordSet.index(currentWord)\n",
    "        baselineRes.append(wordsMostFreqUse[currentWordPos][1])\n",
    "    else:\n",
    "        #If the current word never occured in training set, we'll consider it as NOUN\n",
    "        baselineRes.append(7)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20254\n"
     ]
    }
   ],
   "source": [
    "print(len(baselineRes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Accuracy is 0.8919225831934433\n"
     ]
    }
   ],
   "source": [
    "#Baseline accuracy calculation\n",
    "correct = 0\n",
    "for i in range(0, len(baselineRes)):\n",
    "    if(baselineRes[i]==posDictionary[wordsArrayTest[i][1]]):\n",
    "        correct += 1\n",
    "print(\"Baseline Accuracy is \" + str(correct/len(baselineRes)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#-------------------------------------#\n",
    "#         DIRECT TRANSLATION          #\n",
    "#-------------------------------------#\n",
    "\n",
    "itaEngDict = {}\n",
    "itaEngDict['È0'] = \"is\"\n",
    "itaEngDict['È1'] = \"'s\"\n",
    "itaEngDict['la0'] = 'of'\n",
    "itaEngDict['la1'] = 'it'\n",
    "itaEngDict['spada0'] = 'saber'\n",
    "itaEngDict['laser0'] = 'light'\n",
    "itaEngDict['di0'] = 'of'\n",
    "itaEngDict['di1'] = \"'s\"\n",
    "itaEngDict['tuo0'] = 'your'\n",
    "itaEngDict['padre0'] = 'father'\n",
    "\n",
    "itaEngDict['Ha0'] = 'he'\n",
    "itaEngDict['fatto0'] = 'made'\n",
    "itaEngDict['una0'] = 'a'\n",
    "itaEngDict['mossa0'] = 'move'\n",
    "itaEngDict['leale0'] = 'fair'\n",
    "\n",
    "itaEngDict['Gli0'] = 'the'\n",
    "itaEngDict['ultimi0'] = 'last'\n",
    "itaEngDict['avanzi0'] = 'remnants'\n",
    "itaEngDict['della0'] = 'of'\n",
    "itaEngDict['vecchia0'] = 'old'\n",
    "itaEngDict['Repubblica0'] = 'republic'\n",
    "itaEngDict['sono0'] = 'have'\n",
    "itaEngDict['stati0'] = 'been'\n",
    "itaEngDict['spazzati0'] = 'swept'\n",
    "itaEngDict['via0'] = 'away'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#PoS rules\n",
    "def invertingPosRules(phrase, posTagArray, i, translated):\n",
    "    #Handle Saxon genitive\n",
    "    if((i<len(phrase)-2) & (i>0)):\n",
    "        if((posTagArray[i]=='ADP') & (posTagArray[i+1]=='DET') & (posTagArray[i+2]=='NOUN')):\n",
    "            j=i-1\n",
    "            while(posTagArray[j] == 'NOUN'): \n",
    "                j-=1\n",
    "            translated.insert(j+1, itaEngDict[phrase[i+1]+'0'])\n",
    "            translated.insert(j+2, itaEngDict[phrase[i+2]+'0'])\n",
    "            translated.insert(j+3, itaEngDict[phrase[i]+'1'])\n",
    "            return 3\n",
    "        \n",
    "    # Handle subject's Saxon genitive(\"È la\" --> \"It's\")  \n",
    "    if(i<len(phrase)-1):\n",
    "        if((posTagArray[i]=='AUX') & (posTagArray[i+1]=='DET')):\n",
    "            translated.append(itaEngDict[phrase[i+1]+'1'])\n",
    "            translated.append(itaEngDict[phrase[i]+'1'])\n",
    "            return 2\n",
    "    \n",
    "    #Invert noun and adjective(\"mossa leale\" --> \"fair move\")\n",
    "    if(i<len(phrase)-1):\n",
    "        if((posTagArray[i]=='NOUN') & (posTagArray[i+1]=='ADJ')):\n",
    "            translated.append(itaEngDict[phrase[i+1]+'0'])\n",
    "            translated.append(itaEngDict[phrase[i]+'0'])\n",
    "            return 2\n",
    "    translated.append(itaEngDict[phrase[i]+'0'])\n",
    "    return 1\n",
    "\n",
    "#DIRECT TRANSLATION\n",
    "def translatePhrase(phrase, posTagArray):\n",
    "    translated = []\n",
    "    i=0\n",
    "    while(i<len(phrase)):\n",
    "        incr = invertingPosRules(phrase, posTagArray, i, translated)\n",
    "        i+= incr\n",
    "    return translated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[['È', 'la', 'spada', 'laser', 'di', 'tuo', 'padre'], ['AUX', 'DET', 'NOUN', 'NOUN', 'ADP', 'DET', 'NOUN']], [['Ha', 'fatto', 'una', 'mossa', 'leale'], ['AUX', 'VERB', 'DET', 'NOUN', 'ADJ']], [['Gli', 'ultimi', 'avanzi', 'della', 'vecchia', 'Repubblica', 'sono', 'stati', 'spazzati', 'via'], ['DET', 'ADJ', 'NOUN', 'PROPN', 'ADJ', 'NOUN', 'AUX', 'AUX', 'VERB', 'ADP']]]\n"
     ]
    }
   ],
   "source": [
    "#Testing the translation on the three sample phrase given by the teacher \n",
    "phrases2Translate = [ [phrasesSample[0], resSample[0]], [phrasesSample[1], resSample[1]], [ phrasesSample[2], resSample[2] ] ]\n",
    "print(phrases2Translate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "it 's your father 's saber light \n",
      "he made a fair move \n",
      "the last remnants of old republic have been swept away \n"
     ]
    }
   ],
   "source": [
    "#Translate!\n",
    "for i in range(0, len(phrases2Translate)):\n",
    "    translated = translatePhrase(phrases2Translate[i][0], phrases2Translate[i][1])\n",
    "    for j in range(0, len(translated)):\n",
    "        sys.stdout.write(translated[j]+' ')\n",
    "        sys.stdout.flush()\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
